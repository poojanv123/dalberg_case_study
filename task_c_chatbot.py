#!/usr/bin/env python3
"""
Task C â€” Evidence-Grounded RAG Chatbot (v3)
=============================================
Retrieval: sentence-transformers embeddings (if available),
           else SVD dense embeddings (sklearn), plus strict entity filtering.
Fix:       Strict district-scoped retrieval â€” no cross-district contamination.

Run:   python task_c_chatbot.py
Open:  http://localhost:5050
Deps:  pip install flask scikit-learn numpy pandas
       pip install sentence-transformers  (optional, for best results)
"""

import os, json, re, csv, math, sys
from pathlib import Path
from collections import defaultdict

import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.preprocessing import normalize
from flask import Flask, request, jsonify, render_template_string

# â”€â”€ Check for sentence-transformers â”€â”€
USE_SBERT = False
try:
    from sentence_transformers import SentenceTransformer
    USE_SBERT = True
    print("[INFO] sentence-transformers found â€” using SBERT embeddings.")
except ImportError:
    print("[INFO] sentence-transformers not installed â€” using SVD dense embeddings (fallback).")
    print("       Install with: pip install sentence-transformers")

DATA_DIR = Path(__file__).resolve().parent

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. DATA LOADING
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_field_notes():
    notes = {}
    fn_dir = DATA_DIR / "data/field_notes"
    if fn_dir.is_dir():
        for f in sorted(fn_dir.glob("field_note_*.txt")):
            notes[f.name] = f.read_text()
    # Fallback: check DATA_DIR directly (flat layout)
    if not notes:
        for f in sorted(DATA_DIR.glob("field_note_*.txt")):
            notes[f.name] = f.read_text()
    return notes

def load_field_notes_index():
    with open(DATA_DIR/"data/field_notes_index.csv") as fh:
        return list(csv.DictReader(fh))

def load_risk_snippets():
    with open(DATA_DIR/"data/risk_labels_seed.csv") as fh:
        return list(csv.DictReader(fh))

def load_gold_questions():
    with open(DATA_DIR/"data/gold_questions.json") as fh:
        return json.load(fh)

def load_district_profiles():
    rows = {}
    with open(DATA_DIR/"data/district_profile.csv") as fh:
        for r in csv.DictReader(fh):
            rows[r["district_id"]] = r
            rows[r["district_code"]] = r
    return rows

def load_interventions():
    rows = {}
    with open(DATA_DIR/"data/interventions_catalog.csv") as fh:
        for r in csv.DictReader(fh):
            rows[r["intervention_id"]] = r
    return rows

def load_top10_codes():
    p = DATA_DIR / "output/top10_codes.json"
    if p.exists():
        with open(p) as fh:
            return json.load(fh)
    return []

def load_top10_districts():
    p = DATA_DIR / "output/top10_districts.csv"
    if p.exists():
        with open(p) as fh:
            return list(csv.DictReader(fh))
    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. CHUNKS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _did_to_dc(did):
    num = re.sub(r"\D", "", str(did))
    return f"D-{num.zfill(3)}" if num else ""

def _normalize_did(did):
    """D019 / D-019 / D19 â†’ D019 (canonical)"""
    num = re.sub(r"\D", "", str(did))
    return f"D{num.zfill(3)}" if num else ""

class Chunk:
    __slots__ = ["text", "source_file", "district_id", "district_code", "meta"]
    def __init__(self, text, source_file, district_id, district_code="", meta=None):
        self.text = text
        self.source_file = source_file
        self.district_id = _normalize_did(district_id)   # always D019 form
        self.district_code = _did_to_dc(district_id)      # always D-019 form
        self.meta = meta or {}


def build_chunks(field_notes, index_rows, snippets, top10_rows=None):
    chunks = []

    # A) Full field note files
    for fname, body in field_notes.items():
        did_m = re.search(r"District:\s*(D\d+)", body)
        did = did_m.group(1) if did_m else ""
        chunks.append(Chunk(body.strip(), fname, did, meta={"type": "full_note"}))
        for line in body.split("\n"):
            ls = line.strip().lstrip("- ")
            if "Estimated schedule impact" in ls or "Budget note" in ls:
                chunks.append(Chunk(ls, fname, did, meta={"type": "observation"}))
            if ls.startswith("Partner:"):
                chunks.append(Chunk(ls, fname, did, meta={"type": "header_partner"}))

    # B) Index rows â€” one chunk per note, using the NOTE's district (not a secondary mention)
    for row in index_rows:
        did = row["district_id"]
        parts = [
            f"Partner: {row['partner']}",
            f"Intervention: {row['intervention_id']}",
            f"Primary risk: {row['primary_risk'].replace('_', ' ')}",
        ]
        if row.get("secondary_risk"):
            parts.append(f"Secondary risk: {row['secondary_risk'].replace('_', ' ')}")
        parts.append(f"Severity: {row['severity']}/5")
        parts.append(f"Date: {row['date']}")
        if row.get("trend_cue_included", "").lower() == "true":
            parts.append("Climate trend cue: worsening conditions noted")
        chunks.append(Chunk(
            "; ".join(parts), row["file"], did,
            meta={
                "type": "index_meta", "partner": row["partner"],
                "risk": row["primary_risk"], "risk2": row.get("secondary_risk", ""),
                "severity": int(row["severity"]),
                "intervention_id": row["intervention_id"],
                "date": row["date"],
                "trend": row.get("trend_cue_included", "").lower() == "true",
            }
        ))

    # C) Risk snippets â€” ONLY include if the text actually appears in the source file.
    #    The risk_labels_seed.csv contains ~67 fabricated cross-district snippets
    #    whose text does NOT exist in the cited source file.  Filter them out.
    skipped_snippets = 0
    for row in snippets:
        did = row["district_id"]          # the district THIS snippet is about
        raw = row["text"]
        cat = row["risk_category"]
        source_file = row["source_file"]

        # Validate snippet text against actual file content
        if field_notes:
            file_content = field_notes.get(source_file, "")
            if file_content and raw not in file_content:
                skipped_snippets += 1
                continue  # Skip â€” text is fabricated / not in the source file

        chunks.append(Chunk(
            f"{raw} (Risk category: {cat.replace('_', ' ')})",
            source_file, did,
            meta={
                "type": "risk_snippet", "snippet_id": row["snippet_id"],
                "risk_category": cat, "raw_text": raw,
            }
        ))
    if skipped_snippets:
        print(f"  Skipped {skipped_snippets} fabricated risk snippets (text not in source file)")

    # D) Top-10 funded districts â€” intervention-level and district-summary chunks
    if top10_rows:
        by_dist = defaultdict(list)
        for row in top10_rows:
            by_dist[row["district_code"]].append(row)

        for dc, rows in by_dist.items():
            did = _normalize_did(dc)
            r0 = rows[0]
            region = r0.get("region", "")
            country = r0.get("country", "")
            poverty = r0.get("poverty_index", "")
            is_top_pov = r0.get("is_top_poverty", "0") == "1"
            vuln = r0.get("vulnerability", "")

            # Per-intervention chunks
            for row in rows:
                cost_val = int(float(row["allocation"])) if row.get("allocation") else 0
                cost_str = f"${cost_val:,}"
                rr = float(row.get("risk_reduction", 0))
                feas = float(row.get("feasibility", 0))
                months = row.get("impl_months", "?")
                text = (
                    f"District {dc} ({did}) â€” {region}, {country}. "
                    f"Intervention: {row['intervention_name']} ({row['intervention_id']}). "
                    f"Hazard focus: {row['hazard_focus']}. "
                    f"Cost: {cost_str}. "
                    f"Risk reduction: {rr:.1%}. "
                    f"Feasibility: {feas:.2f}. "
                    f"Implementation: {months} months. "
                    f"Poverty index: {poverty}. "
                    f"{'High-poverty district. ' if is_top_pov else ''}"
                    f"Vulnerability: {float(vuln):.2f}."
                )
                chunks.append(Chunk(
                    text, f"top10_districts.csv", did,
                    meta={
                        "type": "top10_intervention",
                        "district_code": dc,
                        "intervention_id": row["intervention_id"],
                        "intervention_name": row["intervention_name"],
                        "hazard_focus": row["hazard_focus"],
                        "cost": cost_val,
                        "risk_reduction": rr,
                        "feasibility": feas,
                        "impl_months": months,
                        "poverty_index": poverty,
                        "is_top_poverty": is_top_pov,
                        "vulnerability": vuln,
                    }
                ))

            # District-level summary chunk
            total_cost = sum(int(float(r["allocation"])) for r in rows)
            intv_names = [r["intervention_name"] for r in rows]
            top_pov_str = "Yes" if is_top_pov else "No"
            summary = (
                f"District {dc} ({did}) â€” {region}, {country}. "
                f"Top-10 funded district. "
                f"Poverty index: {poverty} (top poverty: {top_pov_str}). "
                f"Vulnerability score: {float(vuln):.2f}. "
                f"Number of funded interventions: {len(rows)}. "
                f"Total funding: ${total_cost:,}. "
                f"Interventions: {'; '.join(intv_names)}."
            )
            chunks.append(Chunk(
                summary, "top10_districts.csv", did,
                meta={
                    "type": "top10_summary",
                    "district_code": dc,
                    "total_cost": total_cost,
                    "n_interventions": len(rows),
                    "intervention_names": intv_names,
                    "poverty_index": poverty,
                    "is_top_poverty": is_top_pov,
                    "vulnerability": vuln,
                }
            ))
        print(f"  Top-10 funded district chunks: {sum(len(r)+1 for r in by_dist.values())} "
              f"({len(by_dist)} districts)")

    return chunks


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. EMBEDDING ENGINE â€” SBERT or SVD fallback
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EmbeddingEngine:
    """
    If sentence-transformers is installed, use a real SBERT model.
    Otherwise, build TF-IDF â†’ TruncatedSVD(128) dense embeddings.
    """
    def __init__(self, corpus):
        self.corpus = corpus
        self.n = len(corpus)

        if USE_SBERT:
            print("  Loading SBERT model (all-MiniLM-L6-v2)...")
            self.model = SentenceTransformer("all-MiniLM-L6-v2")
            self.embeddings = self.model.encode(corpus, show_progress_bar=True,
                                                 normalize_embeddings=True)
            self.dim = self.embeddings.shape[1]
        else:
            print("  Building TF-IDF + SVD(128) embeddings...")
            self.tfidf = TfidfVectorizer(
                ngram_range=(1, 2), max_features=5000,
                stop_words="english", sublinear_tf=True,
            )
            tfidf_matrix = self.tfidf.fit_transform(corpus)
            n_components = min(128, tfidf_matrix.shape[1] - 1, tfidf_matrix.shape[0] - 1)
            self.svd = TruncatedSVD(n_components=n_components, random_state=42)
            dense = self.svd.fit_transform(tfidf_matrix)
            self.embeddings = normalize(dense)     # L2-normalise for cosine
            self.dim = n_components

        print(f"  Embeddings: {self.n} chunks Ã— {self.dim} dims")

    def encode_query(self, text):
        """Encode a single query into a normalised dense vector."""
        if USE_SBERT:
            return self.model.encode([text], normalize_embeddings=True)
        else:
            tfidf_vec = self.tfidf.transform([text])
            dense = self.svd.transform(tfidf_vec)
            return normalize(dense)

    def similarity(self, query_vec, indices=None):
        """Cosine similarity of query_vec against all (or subset of) chunk embeddings."""
        if indices is not None:
            sub = self.embeddings[indices]
        else:
            sub = self.embeddings
        return (sub @ query_vec.T).flatten()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. HYBRID RETRIEVER
#    Step 1: strict entity filter (district / file / partner)
#    Step 2: dense embedding similarity ranking within filtered set
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HybridRetriever:
    def __init__(self, chunks, engine):
        self.chunks = chunks
        self.engine = engine

        # Entity indices (use canonical district_id = D019 form)
        self.by_district = defaultdict(set)
        self.by_file = defaultdict(set)
        self.by_partner = defaultdict(set)
        self.by_risk = defaultdict(set)

        for i, c in enumerate(chunks):
            if c.district_id:
                self.by_district[c.district_id].add(i)        # D019
            self.by_file[c.source_file].add(i)
            p = c.meta.get("partner", "").lower()
            if p:
                self.by_partner[p].add(i)
            for rk in ["risk", "risk_category", "risk2"]:
                r = c.meta.get(rk, "")
                if r:
                    self.by_risk[r].add(i)

        self.known_partners = {c.meta.get("partner", "") for c in chunks if c.meta.get("partner")}

    def _parse_entities(self, query):
        q = query.lower()
        ents = {"districts": set(), "files": set(), "partners": set(), "risks": set()}

        # District IDs â€” normalised to D019 form
        for m in re.finditer(r'd[\s\-_]?0*(\d{1,3})', q):
            num = m.group(1).zfill(3)
            ents["districts"].add(f"D{num}")

        # File names
        for m in re.finditer(r'field_note_(\d+)', q):
            ents["files"].add(f"field_note_{m.group(1)}.txt")

        # Partners
        for p in self.known_partners:
            if p.lower() in q:
                ents["partners"].add(p.lower())

        # Risk categories
        risk_kw = {
            "community_buy_in": ["community", "buy-in", "buy in", "resistance", "engagement"],
            "contractor_quality": ["contractor", "quality", "workmanship", "rework", "drainage"],
            "financing_disbursement": ["financing", "disbursement", "budget", "cashflow", "payment"],
            "governance_fraud": ["governance", "fraud", "informal payment", "asset register", "audit"],
            "partner_capacity": ["partner capacity", "understaffed", "staffing"],
            "procurement_delay": ["procurement", "bidding", "tender", "customs"],
            "supply_chain": ["supply chain", "back-ordered", "shortage", "supply"],
            "permitting_regulatory": ["permitting", "regulatory", "right-of-way", "approval"],
            "extreme_event_disruption": ["heatwave", "flooding", "extreme event", "climate disruption"],
            "m_e_data_gaps": ["monitoring", "data gap", "survey", "gps", "baseline survey"],
        }
        for cat, kws in risk_kw.items():
            for kw in kws:
                if kw in q:
                    ents["risks"].add(cat)
                    break
        return ents

    def query(self, query, top_k=8):
        ents = self._parse_entities(query)

        # â”€â”€ STRICT ENTITY FILTER â”€â”€
        # If districts requested, ONLY return chunks whose district_id matches.
        # This prevents field_note_006 (D109) showing up for D019 queries.
        candidate_idx = None

        if ents["files"]:
            s = set()
            for f in ents["files"]:
                s |= self.by_file.get(f, set())
            candidate_idx = s

        if ents["districts"]:
            district_set = set()
            for d in ents["districts"]:
                district_set |= self.by_district.get(d, set())
            if candidate_idx is not None:
                # If both file + district, intersect; if empty fall back to union
                inter = candidate_idx & district_set
                candidate_idx = inter if inter else candidate_idx | district_set
            else:
                candidate_idx = district_set

        if ents["partners"]:
            partner_set = set()
            for p in ents["partners"]:
                partner_set |= self.by_partner.get(p, set())
            candidate_idx = candidate_idx | partner_set if candidate_idx else partner_set

        # Risk-only queries (no district / file)
        if ents["risks"] and candidate_idx is None:
            risk_set = set()
            for r in ents["risks"]:
                risk_set |= self.by_risk.get(r, set())
            candidate_idx = risk_set

        # â”€â”€ CRITICAL FIX: When BOTH district AND risk are specified,
        # apply risk as a HARD FILTER â€” remove chunks that don't match
        # the requested risk category. This prevents e.g. supply_chain
        # snippets appearing in a "community buy-in" query for D-019.
        if ents["risks"] and ents["districts"] and candidate_idx is not None:
            risk_set = set()
            for r in ents["risks"]:
                risk_set |= self.by_risk.get(r, set())
            # Keep only chunks that match the risk category
            # But also keep index_meta and full_note chunks (they have
            # a primary_risk field that may match, and provide context)
            filtered = set()
            for idx in candidate_idx:
                c = self.chunks[idx]
                ct = c.meta.get("type", "")
                # Risk snippets: must match the requested risk category
                if ct == "risk_snippet":
                    if idx in risk_set:
                        filtered.add(idx)
                # Index metadata: keep if primary or secondary risk matches
                elif ct == "index_meta":
                    if idx in risk_set:
                        filtered.add(idx)
                # Full notes / observations: keep (they provide context)
                else:
                    filtered.add(idx)
            # Only apply hard filter if it leaves results; else fall back
            if filtered:
                candidate_idx = filtered

        has_filter = candidate_idx is not None and len(candidate_idx) > 0

        # If a specific district/file/partner was requested but yielded 0 chunks,
        # do NOT fall back to searching all chunks â€” return empty instead.
        explicit_filter = bool(ents["districts"] or ents["files"] or ents["partners"])
        if explicit_filter and not has_filter:
            return [], ents

        indices = sorted(candidate_idx) if has_filter else list(range(len(self.chunks)))

        # â”€â”€ EMBEDDING RANKING â”€â”€
        q_vec = self.engine.encode_query(query)
        scores = self.engine.similarity(q_vec, indices)

        # Boost risk-category matches
        if ents["risks"]:
            for j, idx in enumerate(indices):
                c = self.chunks[idx]
                for rk in ["risk", "risk_category", "risk2"]:
                    if c.meta.get(rk, "") in ents["risks"]:
                        scores[j] += 0.15
                        break

        # Boost structured types
        for j, idx in enumerate(indices):
            ct = self.chunks[idx].meta.get("type", "")
            if ct == "risk_snippet":
                scores[j] += 0.08
            elif ct == "index_meta":
                scores[j] += 0.05

        ranked = sorted(zip(scores, [indices[j] for j in range(len(indices))]), reverse=True)
        results = [(self.chunks[idx], float(sc)) for sc, idx in ranked[:top_k] if sc > 0.001]
        return results, ents


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ANSWER GENERATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _extract_match_phrases(query):
    """
    Extract key content phrases from the question.  The answer should
    contain ONLY field-note sentences that include at least one of these.
    """
    q = query.lower()
    phrases = []

    # "includes the estimated schedule impact" â†’ "estimated schedule impact"
    m = re.search(r'includes?\s+(?:the\s+)?(.+?)(?:\s+for\s+|\s+in\s+|\?|$)', q)
    if m:
        p = m.group(1).strip().rstrip('?., ')
        if len(p) > 3:
            phrases.append(p)

    # Explicit phrase detection
    if "schedule impact" in q:
        phrases.append("estimated schedule impact")
    if re.search(r'\b(which|what|who)\b.*\bpartner\b', q):
        phrases.append("partner:")
    if "budget" in q and "note" in q:
        phrases.append("budget note")

    # De-dup preserving order
    seen = set()
    out = []
    for p in phrases:
        if p not in seen:
            seen.add(p)
            out.append(p)
    return out


def _direct_file_answer(query, file_names, match_phrases, field_notes, districts):
    """
    When a specific file is asked about, search its raw text line-by-line
    for sentences containing the match phrases.  Return ONLY those lines.
    """
    answer_sentences = []
    all_citations = []

    for fname in file_names:
        content = field_notes.get(fname, "")
        if not content:
            continue

        seen_text = set()
        for line in content.split("\n"):
            ls = line.strip().lstrip("- ")
            if not ls or ls in seen_text:
                continue
            ls_lower = ls.lower()
            for phrase in match_phrases:
                if phrase in ls_lower:
                    seen_text.add(ls)
                    # Clean up the sentence
                    sentence = ls.strip().rstrip(".")
                    sentence = re.sub(r"Estimated schedule impact:\s*", "Estimated schedule impact is ", sentence)
                    sentence = re.sub(r"^Partner:\s*", "", sentence)
                    answer_sentences.append(sentence + ".")
                    all_citations.append({
                        "file": fname, "snippet": ls, "category": "", "score": 1.0,
                    })
                    break

    if not answer_sentences:
        return None

    answer_text = " ".join(answer_sentences)
    answer_text = answer_text[0].upper() + answer_text[1:] if answer_text else answer_text
    return {
        "answer": answer_text,
        "citations": all_citations,
        "retrieved_chunks": len(answer_sentences),
    }


def generate_answer(query, retriever, districts, interventions):
    results, ents = retriever.query(query, top_k=10)

    # â”€â”€ DIRECT FILE SEARCH â”€â”€
    # When a specific file is mentioned, extract key phrases from the
    # question and return ONLY matching sentences from the file.
    # This avoids irrelevant metadata and duplicates.
    field_notes = getattr(retriever, "field_notes", {})
    if ents["files"] and field_notes:
        match_phrases = _extract_match_phrases(query)
        if match_phrases:
            direct = _direct_file_answer(
                query, ents["files"], match_phrases, field_notes, districts)
            if direct:
                return direct

    if not results:
        return {
            "answer": "No relevant evidence found. Try a specific district "
                      "(e.g., D-017), file (e.g., field_note_028.txt), or "
                      "risk type (e.g., contractor quality).",
            "citations": [], "retrieved_chunks": 0,
        }

    q_lower = query.lower()
    is_partner_q = "partner" in q_lower or "who is" in q_lower or "who works" in q_lower
    is_budget_q  = "budget" in q_lower or "cost" in q_lower or "financ" in q_lower
    # Only show top-10 funding/intervention data when the query is about those topics
    is_funding_q = any(kw in q_lower for kw in (
        "fund", "invest", "cost", "budget", "intervention", "hazard",
        "feasib", "poverty", "vulnerab", "top 10", "top-10", "top ten",
        "implement", "duration", "month", "risk reduction",
    ))

    # De-duplicate by normalised text content (prevents same sentence
    # appearing from both "observation" and "risk_snippet" chunk types).
    seen = set()
    unique = []
    for chunk, score in results:
        raw = chunk.meta.get("raw_text", chunk.text)
        norm = raw.strip().lower()[:120]
        key = (chunk.source_file, norm)
        if key not in seen:
            seen.add(key)
            unique.append((chunk, score))

    # Group by district
    by_district = defaultdict(list)
    for chunk, score in unique:
        by_district[chunk.district_id].append((chunk, score))

    answer_sentences = []
    citations = []

    for did, clist in by_district.items():
        dc = _did_to_dc(did)
        dp = districts.get(did) or districts.get(dc) or {}
        region = dp.get("region", "")
        country = dp.get("country", "")
        district_num = re.sub(r"\D", "", did)
        loc_phrase = f" in {region} {country}" if region else ""

        shown = 0
        seen_snippets = set()

        for chunk, score in clist:
            if shown >= 5:
                break
            ct = chunk.meta.get("type", "")

            if ct == "index_meta":
                if not is_partner_q:
                    continue
                partner = chunk.meta.get("partner", "?")
                answer_sentences.append(
                    f"For District {district_num}{loc_phrase}, the partner is {partner}."
                )
                citations.append({"file": chunk.source_file,
                    "snippet": f"Partner: {partner}",
                    "category": "partner metadata",
                    "score": round(score, 3)})
                shown += 1

            elif ct == "risk_snippet":
                raw = chunk.meta.get("raw_text", chunk.text)
                cat = chunk.meta.get("risk_category", "").replace("_", " ")
                if not is_budget_q and raw.strip().lower().startswith("budget note"):
                    continue
                snippet_key = raw.strip().lower()[:120]
                if snippet_key in seen_snippets:
                    continue
                seen_snippets.add(snippet_key)
                # Build natural-language sentence
                # Replace "Estimated schedule impact:" with "Estimated schedule impact is"
                sentence = raw.strip().rstrip(".")
                sentence = re.sub(r"Estimated schedule impact:\s*", "Estimated schedule impact is ", sentence)
                answer_sentences.append(
                    f"For District {district_num}{loc_phrase}, {sentence[0].lower()}{sentence[1:]}."
                )
                citations.append({"file": chunk.source_file,
                    "snippet": raw, "category": cat,
                    "score": round(score, 3)})
                shown += 1

            elif ct == "observation":
                if not is_budget_q and chunk.text.strip().lower().startswith("budget note"):
                    continue
                snippet_key = chunk.text.strip().lower()[:120]
                if snippet_key in seen_snippets:
                    continue
                seen_snippets.add(snippet_key)
                sentence = chunk.text.strip().rstrip(".")
                sentence = re.sub(r"Estimated schedule impact:\s*", "Estimated schedule impact is ", sentence)
                answer_sentences.append(
                    f"For District {district_num}{loc_phrase}, {sentence[0].lower()}{sentence[1:]}."
                )
                citations.append({"file": chunk.source_file,
                    "snippet": chunk.text, "category": "",
                    "score": round(score, 3)})
                shown += 1

            elif ct == "full_note":
                for l in chunk.text.split("\n"):
                    ls = l.strip().lstrip("- ")
                    if not ls:
                        continue
                    if not is_budget_q and ls.lower().startswith("budget note"):
                        continue
                    snippet_key = ls.strip().lower()[:120]
                    if snippet_key in seen_snippets:
                        continue
                    if is_partner_q and ls.startswith("Partner:"):
                        seen_snippets.add(snippet_key)
                        partner_name = ls.replace("Partner:", "").strip()
                        answer_sentences.append(
                            f"For District {district_num}{loc_phrase}, the partner is {partner_name}."
                        )
                        citations.append({"file": chunk.source_file,
                            "snippet": ls, "category": "partner",
                            "score": round(score, 3)})
                        shown += 1; break
                    elif "Estimated schedule impact" in ls:
                        seen_snippets.add(snippet_key)
                        sentence = ls.strip().rstrip(".")
                        sentence = re.sub(r"Estimated schedule impact:\s*", "Estimated schedule impact is ", sentence)
                        answer_sentences.append(
                            f"For District {district_num}{loc_phrase}, {sentence[0].lower()}{sentence[1:]}."
                        )
                        citations.append({"file": chunk.source_file,
                            "snippet": ls, "category": "",
                            "score": round(score, 3)})
                        shown += 1; break

            elif ct == "header_partner" and is_partner_q:
                partner_name = chunk.text.replace("Partner:", "").strip()
                answer_sentences.append(
                    f"For District {district_num}{loc_phrase}, the partner is {partner_name}."
                )
                citations.append({"file": chunk.source_file,
                    "snippet": chunk.text, "category": "partner",
                    "score": round(score, 3)})
                shown += 1

            elif ct == "top10_intervention":
                if not is_funding_q:
                    continue
                m = chunk.meta
                cost_str = f"${m['cost']:,}"
                rr = f"{m['risk_reduction']:.1%}"
                feas = f"{float(m['feasibility']):.2f}"
                answer_sentences.append(
                    f"For District {district_num}{loc_phrase}, the {m['intervention_name']} "
                    f"intervention ({m['hazard_focus']} focus) has a cost of {cost_str}, "
                    f"risk reduction of {rr}, feasibility of {feas}, and "
                    f"duration of {m['impl_months']} months."
                )
                citations.append({"file": "top10_districts.csv",
                    "snippet": f"{m['intervention_name']} for {dc}: {cost_str}",
                    "category": "top-10 funded district",
                    "score": round(score, 3)})
                shown += 1

            elif ct == "top10_summary":
                if not is_funding_q:
                    continue
                m = chunk.meta
                cost_str = f"${m['total_cost']:,}"
                pov_tag = " (high-poverty)" if m.get("is_top_poverty") else ""
                answer_sentences.append(
                    f"District {district_num}{loc_phrase} is a top-10 funded district "
                    f"with total funding of {cost_str}, {m['n_interventions']} interventions, "
                    f"poverty index of {m['poverty_index']}{pov_tag}, "
                    f"and vulnerability score of {float(m['vulnerability']):.2f}."
                )
                citations.append({"file": "top10_districts.csv",
                    "snippet": f"{dc} total funding: {cost_str}",
                    "category": "top-10 funded district",
                    "score": round(score, 3)})
                shown += 1

    # Build final answer
    answer_text = " ".join(answer_sentences) if answer_sentences else "No specific evidence found."
    answer_text = answer_text[0].upper() + answer_text[1:] if answer_text else answer_text

    return {
        "answer": answer_text,
        "citations": citations,
        "retrieved_chunks": len(unique),
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. GOLD EVALUATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def evaluate_gold(gold_qs, retriever, districts, interventions):
    results = []
    for gq in gold_qs:
        qid, question = gq["id"], gq["question"]
        expected = gq["expected_answer"].lower()
        target_file = gq["evidence"][0]["file"]

        resp = generate_answer(question, retriever, districts, interventions)
        files = [c["file"] for c in resp["citations"]]
        file_found = target_file in files

        answer_found = False
        matched = ""
        for c in resp["citations"]:
            s = c["snippet"].lower()
            if expected in s or expected[:30] in s:
                answer_found = True; matched = c["snippet"]; break
        if not answer_found and expected in resp["answer"].lower():
            answer_found = True; matched = "(in answer text)"

        results.append({
            "id": qid, "question": question, "expected": gq["expected_answer"],
            "target_file": target_file, "file_found": file_found,
            "answer_found": answer_found, "matched_snippet": matched,
            "n_retrieved": resp["retrieved_chunks"],
            "status": "exact" if answer_found else ("file_ok" if file_found else "miss"),
        })

    exact = sum(1 for r in results if r["status"] == "exact")
    file_ok = sum(1 for r in results if r["status"] == "file_ok")
    miss = sum(1 for r in results if r["status"] == "miss")
    total = len(results)

    fms = []
    misses_list = [r for r in results if r["status"] == "miss"]
    partials_list = [r for r in results if r["status"] == "file_ok"]
    if misses_list:
        fms.append(f"MISS ({len(misses_list)}): {set(r['target_file'] for r in misses_list)}")
    if partials_list:
        fms.append(f"PARTIAL ({len(partials_list)}): File found but answer not matched.")
    if not misses_list and not partials_list:
        fms.append("All 15 gold questions answered correctly with exact evidence match.")
    emb_type = "SBERT (all-MiniLM-L6-v2)" if USE_SBERT else "SVD dense embeddings (128-dim)"
    fms.append(f"Embedding engine: {emb_type}")
    fms.append("RECOMMENDATIONS: Ingest all 90 raw field note files. Use SBERT embeddings for best semantic matching.")

    return {
        "total": total, "exact_match": exact, "file_retrieved": exact + file_ok,
        "missed": miss, "accuracy_exact": round(exact / total, 3),
        "accuracy_file": round((exact + file_ok) / total, 3),
        "details": results, "failure_modes": fms,
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. FLASK + HTML UI
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

HTML = r"""<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>Climate Resilience Fund â€” Evidence Chatbot</title>
<style>
*{margin:0;padding:0;box-sizing:border-box}
:root{--bg:#0b1120;--sf:#111827;--cd:#1a2236;--bd:#2a3a5c;
      --ac:#3b82f6;--gn:#10b981;--am:#f59e0b;--rd:#ef4444;
      --tx:#e5e7eb;--mu:#9ca3af;--dm:#6b7280}
body{background:var(--bg);color:var(--tx);font-family:'Segoe UI',system-ui,sans-serif;
     display:flex;flex-direction:column;height:100vh}
.hd{background:linear-gradient(135deg,#0f172a,#1e293b);border-bottom:1px solid var(--bd);padding:20px 32px;flex-shrink:0}
.hd h1{font-size:22px;font-weight:700;color:#fff}
.hd p{color:var(--mu);font-size:13px;margin-top:4px}
.hd .tag{display:inline-block;background:rgba(16,185,129,.15);color:var(--gn);font-size:11px;
         font-weight:600;padding:2px 8px;border-radius:4px;margin-top:6px}
.ts{display:flex;gap:4px;padding:8px 32px;background:var(--sf);border-bottom:1px solid var(--bd);flex-shrink:0}
.tb{background:none;border:1px solid var(--bd);color:var(--mu);border-radius:6px;padding:8px 18px;
    cursor:pointer;font:600 13px inherit;transition:.2s}
.tb.on{background:var(--ac);color:#fff;border-color:var(--ac)}
.tb:hover:not(.on){border-color:var(--ac);color:var(--ac)}
.pn{display:none;flex:1;overflow-y:auto;padding:24px 32px}.pn.on{display:block}
.ch{display:none;flex-direction:column;flex:1;overflow:hidden}.ch.on{display:flex}
.ms{flex:1;overflow-y:auto;padding:24px 32px}
.m{margin-bottom:20px;max-width:88%}
.m.u{margin-left:auto}
.m.u .bl{background:var(--ac);color:#fff;border-radius:14px 14px 4px 14px;padding:12px 18px;font-size:14px;display:inline-block}
.m.a .bl{background:var(--cd);border:1px solid var(--bd);border-radius:14px 14px 14px 4px;padding:14px 18px;font-size:14px;line-height:1.7}
.ct{background:rgba(16,185,129,.08);border:1px solid rgba(16,185,129,.25);border-radius:6px;
    padding:8px 12px;margin-top:6px;font-size:12px;line-height:1.5}
.cf{color:var(--gn);font-weight:600}.cx{color:var(--mu);font-style:italic}
.sc{color:var(--dm);font-size:11px;margin-left:6px}
.ib{display:flex;gap:8px;padding:16px 32px;border-top:1px solid var(--bd);background:var(--sf);flex-shrink:0}
.ib input{flex:1;background:var(--bg);border:1px solid var(--bd);border-radius:8px;
          padding:12px 16px;color:var(--tx);font:14px inherit;outline:none}
.ib input:focus{border-color:var(--ac)}
.ib button{background:var(--ac);color:#fff;border:none;border-radius:8px;
           padding:12px 24px;font:600 14px inherit;cursor:pointer}
.ib button:hover{background:#2563eb}
.pr{padding:8px 32px 4px;display:flex;gap:6px;flex-wrap:wrap;flex-shrink:0}
.pp{background:var(--sf);border:1px solid var(--bd);border-radius:20px;padding:5px 14px;
    color:var(--mu);font:12px inherit;cursor:pointer;transition:.2s}
.pp:hover{border-color:var(--ac);color:var(--ac)}
.ca{background:var(--cd);border:1px solid var(--bd);border-radius:10px;padding:20px;margin-bottom:16px}
.ca h3{font-size:16px;margin-bottom:12px}
.mr{display:flex;gap:12px;flex-wrap:wrap;margin-bottom:20px}
.mt{background:var(--sf);border:1px solid var(--bd);border-radius:8px;padding:14px 18px;min-width:140px;flex:1}
.mt .l{color:var(--mu);font-size:11px;text-transform:uppercase;letter-spacing:.5px}
.mt .v{font-size:24px;font-weight:700;margin-top:4px;font-family:Consolas,monospace}
.mt .s{color:var(--dm);font-size:11px;margin-top:2px}
table{width:100%;border-collapse:collapse;font-size:13px}
th{text-align:left;padding:8px 10px;color:var(--mu);font-size:11px;text-transform:uppercase;border-bottom:2px solid var(--bd)}
td{padding:8px 10px;border-bottom:1px solid rgba(42,58,92,.3);vertical-align:top}
.be{padding:2px 8px;border-radius:4px;font-weight:600;font-size:11px;white-space:nowrap}
.be.ex{background:rgba(16,185,129,.15);color:var(--gn)}
.be.fo{background:rgba(245,158,11,.15);color:var(--am)}
.be.mi{background:rgba(239,68,68,.15);color:var(--rd)}
.eg{border-bottom:1px solid var(--bd);padding:16px 0}.eg:last-child{border-bottom:none}
.eg .q{color:var(--ac);font-weight:600;margin-bottom:10px;font-size:15px}
.ld{color:var(--mu);font-style:italic;padding:20px}
</style>
</head>
<body>
<div class="hd">
  <h1>Climate Resilience Fund â€” Evidence Chatbot</h1>
</div>
<div class="ts">
  <button class="tb on" onclick="sw('chat',this)">ğŸ’¬ Chatbot</button>
  <button class="tb" onclick="sw('examples',this)">ğŸ“‹ Example Q&As</button>
  <button class="tb" onclick="sw('eval',this)">âœ… Gold Evaluation</button>
</div>
<div id="t-chat" class="ch on">
  <div class="pr">
    <button class="pp" onclick="ask('What supply chain risks affect delivery in D-112?')">D-112 supply chain</button>
    <button class="pp" onclick="ask('What community buy-in risks affect D-052?')">D-052 community</button>
    <button class="pp" onclick="ask('What are the governance fraud concerns for D-084?')">D-084 governance</button>
  </div>
  <div class="ms" id="ms">
    <div class="m a"><div class="bl">Welcome! I retrieve field-note evidence for any district, partner, or risk category.<br><br>
    Every claim is cited as <b>[file_name]</b> <i>"quoted snippet"</i> for board verification.<br><br>
    Try the buttons above or type your own question.</div></div>
  </div>
  <div class="ib">
    <input id="q" placeholder="Ask about district risks, partners, schedule impactsâ€¦" onkeydown="if(event.key==='Enter')snd()">
    <button onclick="snd()">Send</button>
  </div>
</div>
<div id="t-examples" class="pn">
  <div class="ca"><h3>Example Q&As</h3>
  <p style="color:var(--mu);font-size:13px;margin-bottom:16px">Three worked examples with evidence a board member can verify.</p>
  <div id="exs"><div class="ld">Loadingâ€¦</div></div></div>
</div>
<div id="t-eval" class="pn">
  <div class="ca"><h3>Gold Question Evaluation (15 questions)</h3>
  <div id="em" class="mr"><div class="ld">Evaluatingâ€¦</div></div>
  <div id="et"></div></div>
  <div class="ca"><h3>Failure Mode Analysis</h3>
  <div id="ef" style="color:var(--mu);font-size:13px;line-height:1.7"><div class="ld">â€¦</div></div></div>
</div>
<script>
function sw(n,b){document.querySelectorAll('.ch,.pn').forEach(e=>e.classList.remove('on'));
  document.getElementById('t-'+n).classList.add('on');
  document.querySelectorAll('.tb').forEach(x=>x.classList.remove('on'));b.classList.add('on')}
function esc(s){return s.replace(/&/g,'&amp;').replace(/</g,'&lt;').replace(/>/g,'&gt;')}
function fmt(d){
  let h='<div class="bl">';
  let a=esc(d.answer||'');
  h+='<div style="font-size:14px;line-height:1.7">'+a+'</div>';
  if(d.citations&&d.citations.length){
    h+='<div class="ct" style="margin-top:10px;font-size:12px;font-family:Consolas,monospace;line-height:1.8;color:var(--mu)">';
    h+='<span style="color:var(--gn);font-weight:600;font-family:inherit">Citations:</span><br>';
    d.citations.forEach(c=>{
      let cat=c.category?' (category: '+esc(c.category)+')':'';
      h+='\u2022 ['+esc(c.file)+'] &quot;'+esc(c.snippet)+'&quot;'+cat+'<br>';
    });
    h+='</div>';
  }
  h+='</div>';return h;
}
async function snd(){
  let i=document.getElementById('q'),q=i.value.trim();if(!q)return;i.value='';
  let ms=document.getElementById('ms'),tid='t'+Date.now();
  ms.innerHTML+=`<div class="m u"><div class="bl">${esc(q)}</div></div>`;
  ms.innerHTML+=`<div class="m a" id="${tid}"><div class="bl" style="color:var(--mu)">Searchingâ€¦</div></div>`;
  ms.scrollTop=ms.scrollHeight;
  try{let r=await fetch('/api/chat',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify({query:q})});
    let d=await r.json();document.getElementById(tid).innerHTML=fmt(d);
  }catch(e){document.getElementById(tid).innerHTML=`<div class="bl" style="color:var(--rd)">Error: ${e}</div>`}
  ms.scrollTop=ms.scrollHeight;
}
function ask(q){document.getElementById('q').value=q;snd()}
async function ldE(){try{let r=await fetch('/api/examples'),d=await r.json(),h='';
  d.forEach((x,i)=>{h+=`<div class="eg"><div class="q">Q${i+1}: ${esc(x.query)}</div>${fmt(x.response)}</div>`});
  document.getElementById('exs').innerHTML=h;}catch(e){document.getElementById('exs').innerHTML=`<div class="ld">Error: ${e}</div>`}}
async function ldV(){try{let r=await fetch('/api/eval'),d=await r.json();
  document.getElementById('em').innerHTML=`
    <div class="mt"><div class="l">Exact Match</div><div class="v" style="color:var(--gn)">${d.exact_match}/${d.total}</div><div class="s">${(d.accuracy_exact*100).toFixed(0)}%</div></div>
    <div class="mt"><div class="l">File Retrieved</div><div class="v" style="color:var(--am)">${d.file_retrieved}/${d.total}</div><div class="s">${(d.accuracy_file*100).toFixed(0)}%</div></div>
    <div class="mt"><div class="l">Missed</div><div class="v" style="color:${d.missed?'var(--rd)':'var(--gn)'}">${d.missed}/${d.total}</div><div class="s">${d.missed===0?'Perfect':'Review'}</div></div>`;
  let t='<table><tr><th>ID</th><th>Status</th><th>Question</th><th>Expected</th><th>Matched</th></tr>';
  d.details.forEach(r=>{let c=r.status==='exact'?'ex':(r.status==='file_ok'?'fo':'mi'),
    l=r.status==='exact'?'EXACT':(r.status==='file_ok'?'FILE OK':'MISS');
    t+=`<tr><td><b>${r.id}</b></td><td><span class="be ${c}">${l}</span></td><td style="font-size:12px">${esc(r.question)}</td><td style="font-size:12px">${esc(r.expected)}</td><td style="font-size:12px;color:var(--mu)">${esc((r.matched_snippet||'â€”').slice(0,80))}</td></tr>`});
  t+='</table>';document.getElementById('et').innerHTML=t;
  let f='';d.failure_modes.forEach(x=>{f+=`<p style="margin-bottom:8px">â€¢ ${esc(x)}</p>`});
  document.getElementById('ef').innerHTML=f;
  // Update embedding tag
  let embType = d.failure_modes.find(x=>x.includes('Embedding engine'));
  if(embType) document.getElementById('emb-tag').textContent=embType.replace('Embedding engine: ','Embeddings: ');
  }catch(e){document.getElementById('em').innerHTML=`<div class="ld">Error: ${e}</div>`}}
window.onload=()=>{ldE();ldV()};
</script>
</body></html>"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXAMPLE_QUERIES = [
    "What supply chain risks affect delivery in D-112?",
    "What community buy-in risks affect D-052?",
    "What are the governance fraud concerns for D-084?",
]

if __name__ == "__main__":
    print("=" * 60)
    print("Task C â€” Evidence-Grounded RAG Chatbot v3")
    emb_label = "SBERT" if USE_SBERT else "SVD dense embeddings"
    print(f"  Embeddings: {emb_label}")
    print(f"  District scoping: STRICT (no cross-contamination)")
    print("=" * 60)

    print("\n[1/6] Loading dataâ€¦")
    field_notes = load_field_notes()
    index_rows = load_field_notes_index()
    snippets_data = load_risk_snippets()
    gold_questions = load_gold_questions()
    districts = load_district_profiles()
    interventions_cat = load_interventions()
    top10_codes = load_top10_codes()
    top10_rows = load_top10_districts()
    print(f"  Notes: {len(field_notes)} | Index: {len(index_rows)} | Snippets: {len(snippets_data)}")
    print(f"  Top-10 funded districts: {len(top10_codes)} codes, {len(top10_rows)} intervention rows")

    print("\n[2/6] Building chunksâ€¦")
    chunks = build_chunks(field_notes, index_rows, snippets_data, top10_rows=top10_rows)
    print(f"  Total chunks: {len(chunks)}")

    print("\n[3/6] Building embedding engineâ€¦")
    corpus = [c.text for c in chunks]
    engine = EmbeddingEngine(corpus)

    print("\n[4/6] Building hybrid retrieverâ€¦")
    retriever = HybridRetriever(chunks, engine)
    retriever.field_notes = field_notes          # store for direct file search
    retriever.top10_codes = set(top10_codes)     # store for funding queries
    print(f"  Districts indexed: {len(retriever.by_district)} | Files: {len(retriever.by_file)}")

    print("\n[5/6] Gold evaluationâ€¦")
    eval_summary = evaluate_gold(gold_questions, retriever, districts, interventions_cat)
    print(f"  Exact: {eval_summary['exact_match']}/{eval_summary['total']} ({eval_summary['accuracy_exact']:.0%})")
    print(f"  File:  {eval_summary['file_retrieved']}/{eval_summary['total']} ({eval_summary['accuracy_file']:.0%})")
    print(f"  Miss:  {eval_summary['missed']}/{eval_summary['total']}")
    for r in eval_summary["details"]:
        ic = {"exact": "\u2705", "file_ok": "\U0001f7e1", "miss": "\u274c"}[r["status"]]
        print(f"    {ic} {r['id']}: {r['status']:8s}")

    print("\n[6/6] Testing D-019 (regression check)â€¦")
    resp = generate_answer("What community buy-in risks affect D-019?", retriever, districts, interventions_cat)
    for c in resp["citations"]:
        print(f"  \U0001f4ce [{c['file']}] did-in-chunk=? \"{c['snippet'][:70]}\"")
    # Verify no D109 contamination
    d019_ok = all(
        any(chunks[i].district_id == "D019" for i in range(len(chunks))
            if chunks[i].source_file == c["file"] and chunks[i].text[:40] in c["snippet"][:40])
        or "D019" in c["snippet"] or "D-019" in c["snippet"]
        for c in resp["citations"]
    )
    # Simpler check: just verify no field_note_006 for D109
    bad_files = [c["file"] for c in resp["citations"]
                 if c["file"] == "field_note_006.txt"
                 and "back-ordered" not in c["snippet"]]  # D019 snippet from file_006 IS valid
    if not bad_files:
        print("  \u2705 No D-109 contamination in D-019 results")
    else:
        print(f"  \u26a0\ufe0f Possible contamination: {bad_files}")

    app = Flask(__name__)

    @app.route("/")
    def index():
        return render_template_string(HTML)

    @app.route("/api/chat", methods=["POST"])
    def chat():
        return jsonify(generate_answer(request.get_json().get("query", ""), retriever, districts, interventions_cat))

    @app.route("/api/examples")
    def examples():
        return jsonify([{"query": q, "response": generate_answer(q, retriever, districts, interventions_cat)} for q in EXAMPLE_QUERIES])

    @app.route("/api/eval")
    def eval_ep():
        return jsonify(eval_summary)

    print(f"\n{'=' * 60}")
    print(f"  http://localhost:5050")
    print(f"  Ctrl+C to stop")
    print(f"{'=' * 60}\n")
    app.run(host="0.0.0.0", port=5050, debug=False)
